{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "mDgbUHAGgjLW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arshhad45/EDA/blob/main/Brain_Tumor_MRI_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual/Team\n",
        "##### **Team Member 1 -** - Syed Arshad A"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project focused on building a deep learning-based image classification system to detect and classify brain tumors using MRI scans. Leveraging both a custom Convolutional Neural Network (CNN) and transfer learning with pretrained models (e.g., ResNet50, EfficientNetB0), the solution classifies MRI images into multiple tumor categories. The system was deployed via a Streamlit web app for real-time predictions.\n",
        "\n",
        "Key components of the project include thorough data preprocessing (normalization, resizing), extensive data augmentation to improve generalization, and the use of callbacks like EarlyStopping and ModelCheckpoint during model training. Comprehensive evaluation metrics (accuracy, precision, recall, F1-score, confusion matrix) were used to compare model performance and select the most effective model for deployment.\n",
        "\n",
        "The project also demonstrates practical use cases in AI-assisted medical diagnosis, early detection, research support, and telemedicine integration, making it highly relevant for real-world healthcare applications."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/arshhad45"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Develop a deep learning-based model to accurately classify brain MRI images into different tumor types, improving early diagnosis and assisting radiologists with fast, reliable predictions. The solution should also include a user-friendly web interface for real-time image-based predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "\n",
        "# Image Processing\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Model Evaluation\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import itertools\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Deployment - Streamlit\n",
        "import streamlit as st\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/Tumour'\n",
        "print(os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "id": "2xsUm582IJvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KECv0qlZUqEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/Tumour/train\"\n",
        "val_path = \"/content/drive/MyDrive/Tumour/valid\"\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN Model"
      ],
      "metadata": {
        "id": "3LG2BNrSZ2MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_custom_cnn(input_shape=(224, 224, 3), num_classes=4):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "h03TLyhlZ3jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Custom CNN\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint('custom_cnn_model.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "# Build the custom CNN model\n",
        "cnn_model = build_custom_cnn(input_shape=IMAGE_SIZE + (3,), num_classes=train_generator.num_classes)\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_cnn = cnn_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "NL0gU-1PbIxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transfer Learning Model (ResNet50)\n",
        "\n",
        "def build_transfer_model(base_model, preprocess_func, input_shape=(224, 224, 3), num_classes=4):\n",
        "    base = base_model(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    base.trainable = False  # freeze base\n",
        "\n",
        "    x = base.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base.input, outputs=output)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "maIaxIORbloh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build & Train with ResNet50:\n",
        "resnet_model = build_transfer_model(ResNet50, resnet_preprocess)\n",
        "resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint('resnet_model.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "history_resnet = resnet_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "id": "DWbZRXdRbyXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "# Evaluate on validation data\n",
        "val_loss, val_acc = resnet_model.evaluate(val_generator)\n",
        "print(f\"Validation Accuracy: {val_acc:.2f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "Y_pred = resnet_model.predict(val_generator)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "y_true = val_generator.classes\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=val_generator.class_indices.keys()))\n"
      ],
      "metadata": {
        "id": "gwKVYjO_b5dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save Trained Models\n",
        "cnn_model.save('custom_cnn_model.h5', save_format='h5')\n",
        "resnet_model.save(\"resnet50_model.h5\")\n"
      ],
      "metadata": {
        "id": "OmUUU3JacBx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare Models\n",
        "def plot_history(history, title):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "    plt.title(f'{title} - Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title(f'{title} - Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history_cnn, \"Custom CNN\")\n",
        "plot_history(history_resnet, \"ResNet50\")\n"
      ],
      "metadata": {
        "id": "0bMwNld4cFIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Set page config\n",
        "st.set_page_config(page_title=\"Brain Tumor MRI Classifier\", layout=\"centered\")\n",
        "\n",
        "# Load model\n",
        "model = load_model(\"custom_cnn_model.h5\")  # or \"resnet50_model.h5\"\n",
        "class_names = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
        "\n",
        "# Title and description\n",
        "st.title(\"🧠 Brain Tumor MRI Classification\")\n",
        "st.write(\"Upload an MRI brain scan to predict the tumor type.\")\n",
        "\n",
        "# File upload\n",
        "uploaded_file = st.file_uploader(\"Choose an MRI image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_image(image, target_size=(224, 224)):\n",
        "    image = image.resize(target_size)\n",
        "    img_array = img_to_array(image)\n",
        "    img_array = img_array / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "# Predict\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file).convert('RGB')\n",
        "    st.image(image, caption='Uploaded Image', use_column_width=True)\n",
        "\n",
        "    st.write(\"⏳ Classifying...\")\n",
        "    processed_image = preprocess_image(image)\n",
        "    prediction = model.predict(processed_image)\n",
        "    predicted_class = class_names[np.argmax(prediction)]\n",
        "    confidence = np.max(prediction) * 100\n",
        "\n",
        "    st.success(f\"🔍 Prediction: **{predicted_class}**\")\n",
        "    st.info(f\"📊 Confidence: **{confidence:.2f}%**\")"
      ],
      "metadata": {
        "id": "3HdocABd5-a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c594ca81"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "NGROK_AUTH_TOKEN = userdata.get('ngrok')\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7d8ce9b"
      },
      "source": [
        "# Kill any previous tunnels if open\n",
        "!pkill streamlit\n",
        "!pkill ngrok\n",
        "import time\n",
        "time.sleep(2) # Add a small delay\n",
        "\n",
        "# Start the streamlit app in the background\n",
        "!nohup streamlit run app.py &\n",
        "\n",
        "# Wait a few seconds and expose the port\n",
        "# Use the recommended way to specify the port\n",
        "public_url = ngrok.connect(addr=8501, proto='http')\n",
        "print(\"Streamlit app is live at:\", public_url)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}